import scrapy
from coursespider.items import CourseItem
from scrapy_playwright.page import PageMethod


class MoocwangSpider(scrapy.Spider):
    name = "moocwang"
    allowed_domains = ["imooc.com"]

    categories = {
        "fe": "å‰ç«¯å¼€å‘",
        "be": "åç«¯å¼€å‘",
        "mobile": "ç§»åŠ¨å¼€å‘",
        "algorithm": "è®¡ç®—æœºåŸºç¡€",
        "nt": "å‰æ²¿æŠ€æœ¯",
        "cb": "äº‘è®¡ç®—&å¤§æ•°æ®",
        "op": "è¿ç»´&æµ‹è¯•",
        "data": "æ•°æ®åº“",
        "photo": "äº§å“è®¾è®¡",
        "ms": "æ±‚èŒé¢è¯•",
        "em": "åµŒå…¥å¼å¼€å‘",
        "AI": "AIäººå·¥æ™ºèƒ½",
    }

    def start_requests(self):
        for code, name in self.categories.items():
            url = f"https://www.imooc.com/course/list?c={code}"
            yield scrapy.Request(
                url,
                meta={
                    "playwright": True,
                    "playwright_include_page": True,
                    "playwright_page_methods": [PageMethod("wait_for_timeout", 3000)],
                    "category": name,
                },
                callback=self.parse,
            )

    def parse(self, response):
        category = response.meta.get("category", "æœªçŸ¥åˆ†ç±»")
        self.logger.info(f"ğŸ§­ æ­£åœ¨æŠ“å–åˆ†ç±»: {category}")

        courses = response.xpath('//a[contains(@class, "item")]')
        self.logger.info(f"ğŸ“¦ æœ¬é¡µè¯¾ç¨‹æ•°é‡: {len(courses)}")

        for course in courses:
            title = course.xpath('./p[@class="title ellipsis2"]/text()').get(default="").strip()
            if not title:
                continue  # âŒ è·³è¿‡æ— æ•ˆè¯¾ç¨‹ï¼ˆæ²¡æœ‰æ ‡é¢˜ï¼‰

            href = course.xpath('./@href').get()
            url = response.urljoin(href) if href else ""

            item = CourseItem()
            item["title"] = title
            item["url"] = url
            item["platform"] = "æ…•è¯¾ç½‘"
            item["school"] = ""
            item["teacher"] = ""
            item["description"] = ""
            item["learners"] = self.parse_learners(course.xpath('./p[@class="one"]/text()').get(default=""))
            item["tags"] = category
            item["rating"] = None

            # âœ… è·³è½¬è¯·æ±‚è¯¾ç¨‹è¯¦æƒ…é¡µä»¥æå–ç®€ä»‹
            yield scrapy.Request(
                url,
                callback=self.parse_detail,
                meta={"item": item},
                dont_filter=True,
            )

    def parse_detail(self, response):
        item = response.meta["item"]
        desc = response.xpath('//div[contains(@class, "course-description")]/text()').get(default="").strip()
        item["description"] = desc
        yield item

    def parse_learners(self, text):
        import re
        match = re.search(r'(\d[\d,]*)', text.replace(",", ""))
        return int(match.group(1)) if match else 0
